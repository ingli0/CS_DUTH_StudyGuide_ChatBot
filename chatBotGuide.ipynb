{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "M25NT2SRr4si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "np7WaFYdrXos"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-\"\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-hub unstructured\n"
      ],
      "metadata": {
        "id": "TnbxpLYwr4AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!wget \"https://cs.duth.gr/cs_hosting/attachments/webpages/el_study_guide.pdf\" -O data/el_study_guide.pdf\n"
      ],
      "metadata": {
        "id": "popLBF85t9OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ],
      "metadata": {
        "id": "j1be1FgDuJ2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"unstructured[pdf]\"\n",
        "!pip uninstall -y unstructured\n"
      ],
      "metadata": {
        "id": "T7qem60uvwFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "from pathlib import Path\n",
        "\n",
        "# specify the file name\n",
        "file_name = \"el_study_guide.pdf\"\n",
        "\n",
        "documents = SimpleDirectoryReader(\"./data\").load_data()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XzaaKmsEtGyi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(documents)"
      ],
      "metadata": {
        "id": "8z-73OX8sfDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex, StorageContext\n",
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.chunk_size = 512\n",
        "\n",
        "# specify the file name\n",
        "file_name = \"el_study_guide.pdf\"\n",
        "\n",
        "# filter out the specific document\n",
        "el_study_guide = [doc for doc in documents if doc.metadata['file_name'] == file_name]\n",
        "\n",
        "# initialize storage context\n",
        "storage_context = StorageContext.from_defaults()\n",
        "\n",
        "# create index from documents\n",
        "cur_index = VectorStoreIndex.from_documents(\n",
        "    el_study_guide,\n",
        "    storage_context=storage_context,\n",
        ")\n",
        "\n",
        "# persist the storage context\n",
        "storage_context.persist(persist_dir=f\"./storage/{file_name}\")\n"
      ],
      "metadata": {
        "id": "7z4gvUhdz63M"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import load_index_from_storage\n",
        "\n",
        "# specify the file name\n",
        "file_name = \"el_study_guide.pdf\"\n",
        "\n",
        "# initialize storage context\n",
        "storage_context = StorageContext.from_defaults(\n",
        "    persist_dir=f\"./storage/{file_name}\"\n",
        ")\n",
        "\n",
        "# load index from storage\n",
        "cur_index = load_index_from_storage(\n",
        "    storage_context,\n",
        ")\n"
      ],
      "metadata": {
        "id": "qyfJwMyL0E2j"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "\n",
        "# specify the file name\n",
        "file_name = \"el_study_guide.pdf\"\n",
        "\n",
        "# create QueryEngineTool for the specific file\n",
        "query_engine_tool = QueryEngineTool(\n",
        "    query_engine=cur_index.as_query_engine(),\n",
        "    metadata=ToolMetadata(\n",
        "        name=f\"vector_index_{file_name}\",\n",
        "        description=\"useful for when you want to answer queries about the guide of the university\",\n",
        "    ),\n",
        ")\n"
      ],
      "metadata": {
        "id": "SI0JZaLK0WvL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
        "\n",
        "# specify the file name\n",
        "file_name = \"el_study_guide.pdf\"\n",
        "\n",
        "# create SubQuestionQueryEngine for the specific file\n",
        "query_engine = SubQuestionQueryEngine.from_defaults(\n",
        "    query_engine_tools=[query_engine_tool],\n",
        "    llm=OpenAI(model=\"gpt-3.5-turbo\" , temperature = 0.5),\n",
        ")\n"
      ],
      "metadata": {
        "id": "IdvkzNuf1CSm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine_tool = QueryEngineTool(\n",
        "    query_engine=query_engine,\n",
        "    metadata=ToolMetadata(\n",
        "        name=\"sub_question_query_engine\",\n",
        "        description=\"useful for when you want to answer queries about the guide of the university\",\n",
        "    ),\n",
        ")\n"
      ],
      "metadata": {
        "id": "OyOFfKTz1QsV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "individual_query_engine_tools = [query_engine_tool]\n",
        "tools = individual_query_engine_tools\n"
      ],
      "metadata": {
        "id": "FARVxubl1a29"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.agent.openai import OpenAIAgent\n",
        "\n",
        "agent = OpenAIAgent.from_tools(tools, verbose=True)"
      ],
      "metadata": {
        "id": "Xc1Zi5l711UA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = OpenAIAgent.from_tools(tools)  # verbose=False by default\n",
        "\n",
        "while True:\n",
        "    text_input = input(\"ðŸ‘¦: \")\n",
        "    if text_input == \"ðŸ¤–\":\n",
        "        break\n",
        "    response = agent.chat(text_input)\n",
        "    print(f\"Agent: {response}\")"
      ],
      "metadata": {
        "id": "C7LQr5NK2sEk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}